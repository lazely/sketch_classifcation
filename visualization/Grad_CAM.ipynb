{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGAI8Fxnvurq",
        "outputId": "5f8025b7-4306-4010-a298-2020f8598c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/My Drive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDtHfKdBwrKo",
        "outputId": "e72c496c-1ff5-4ae7-a1c5-edd852fcc11d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchcam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urBbacXe06yE",
        "outputId": "e480d932-5a61-42e3-bd31-460d3e2a7e52"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcam\n",
            "  Downloading torchcam-0.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchcam) (1.26.4)\n",
            "Requirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (9.4.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from torchcam) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n",
            "Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m874.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcam\n",
            "Successfully installed torchcam-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchcam.methods import GradCAM\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "F5RukXWMw70W"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#베이스 라인 마지막에 추가\n",
        "def visualize_gradcam(\n",
        "        model: torch.nn.Module,\n",
        "        device: torch.device,\n",
        "        dataloader: DataLoader,\n",
        "        target_layer: str,\n",
        "        image_index: int\n",
        "    ):\n",
        "    # Grad-CAM 추출기를 초기화\n",
        "    cam_extractor = GradCAM(model, target_layer)\n",
        "\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # 시각화를 위한 Figure를 생성\n",
        "\n",
        "    # 데이터 로더에서 배치를 반복\n",
        "    current_index = 0\n",
        "\n",
        "    for inputs in dataloader:\n",
        "\n",
        "        inputs = inputs.to(device)  # 입력 이미지를 장치로 이동\n",
        "\n",
        "        outputs = model(inputs)  # 모델을 통해 예측을 수행\n",
        "        _, preds = torch.max(outputs, 1)  # 예측된 클래스 인덱스를 가져오는 부분\n",
        "\n",
        "        # 배치 내의 각 이미지에 대해 처리합니다.\n",
        "        for j in range(inputs.size(0)):\n",
        "\n",
        "            if current_index == image_index:\n",
        "\n",
        "                # CAM을 가져오는 부분\n",
        "                cam = cam_extractor(preds[j].item(), outputs[j].unsqueeze(0))[0]\n",
        "\n",
        "                # CAM을 1채널로 변환하는 부분\n",
        "                cam = cam.mean(dim=0).cpu().numpy()\n",
        "\n",
        "                # CAM을 원본 이미지 크기로 리사이즈하는 부분\n",
        "                cam = cv2.resize(cam, (inputs[j].shape[2], inputs[j].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "                # CAM을 정규화 부분\n",
        "                cam = (cam - cam.min()) / (cam.max() - cam.min())  # 정규화\n",
        "\n",
        "                # CAM을 0-255 범위로 변환\n",
        "                cam = np.uint8(255 * cam)\n",
        "\n",
        "                # 컬러맵을 적용하여 RGB 이미지로 변환\n",
        "                cam = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "                cam = cv2.cvtColor(cam, cv2.COLOR_BGR2RGB)  # BGR에서 RGB로 변환\n",
        "\n",
        "\n",
        "\n",
        "                # 입력 이미지가 1채널 또는 3채널인지 확인하고 처리\n",
        "                input_image = inputs[j].cpu().numpy().transpose((1, 2, 0))\n",
        "\n",
        "                if input_image.shape[2] == 1:  # 1채널 이미지인 경우\n",
        "\n",
        "                    input_image = np.squeeze(input_image, axis=2)  # (H, W, 1) -> (H, W)\n",
        "\n",
        "                    input_image = np.stack([input_image] * 3, axis=-1)  # (H, W) -> (H, W, 3)로 변환하여 RGB처럼 만듭니다.\n",
        "\n",
        "                else:  # 3채널 이미지인 경우\n",
        "\n",
        "                    input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
        "\n",
        "                    input_image = (input_image * 255).astype(np.uint8)  # 정규화된 이미지를 8비트 이미지로 변환\n",
        "\n",
        "\n",
        "\n",
        "                # 오리지널 이미지\n",
        "                axes[0].imshow(input_image)\n",
        "\n",
        "                axes[0].set_title(\"Original Image\")\n",
        "\n",
        "                axes[0].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "                # Grad-CAM 이미지\n",
        "                axes[1].imshow(cam)\n",
        "\n",
        "                axes[1].set_title(\"Grad-CAM Image\")\n",
        "\n",
        "                axes[1].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "                # 오버레이된 이미지 생성\n",
        "                overlay = cv2.addWeighted(input_image, 0.5, cam, 0.5, 0)\n",
        "\n",
        "                axes[2].imshow(overlay)\n",
        "\n",
        "                axes[2].set_title(\"Overlay Image\")\n",
        "\n",
        "                axes[2].axis('off')\n",
        "\n",
        "\n",
        "\n",
        "                plt.show()  # 시각화\n",
        "\n",
        "                return\n",
        "\n",
        "            current_index += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "HjaFaZzRxuKE",
        "outputId": "fd3a398a-90cf-41dd-d076-0ec468a0048c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d370d5cf04b3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#베이스 라인 마지막에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m def visualize_gradcam(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#사용한 모델의 마지막 컨볼루션 레이어 찾기\n",
        "print(model)\n",
        "\n",
        "TimmModel(\n",
        "\n",
        "  (model): ResNet(\n",
        "\n",
        "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "    (act1): ReLU(inplace=True)\n",
        "\n",
        "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
        "\n",
        "    (layer1): Sequential(\n",
        "\n",
        "      (0): BasicBlock(\n",
        "\n",
        "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        (act1): ReLU(inplace=True)\n",
        "\n",
        "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        (act2): ReLU(inplace=True)\n",
        "\n",
        "      )\n",
        "\n",
        "      ...\n",
        "\n",
        "    )\n",
        "\n",
        "    (layer4): Sequential(\n",
        "\n",
        "      (0): BasicBlock(\n",
        "\n",
        "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "\n",
        "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        (act1): ReLU(inplace=True)\n",
        "\n",
        "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "        (act2): ReLU(inplace=True)\n",
        "\n",
        "      )\n",
        "\n",
        "      ...\n",
        "\n",
        "    )\n",
        "\n",
        "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
        "\n",
        "    (fc): Linear(in_features=512, out_features=500, bias=True)\n",
        "\n",
        "  )\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "jGGTyGA21KOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이스라인에서 사용된 모델은 timm라이브러리의 ResNet모델입니다. 이 구조에서 ‘layer4’의 마지막 블록의 활성화 함수를 target_layer로 설정합니다.\n",
        "#모델에 따라 수정 필요\n",
        "\n",
        "#Grad-CAM 시각화\n",
        "# 모델의 타겟 레이어 설정 (layer4의 마지막 블록의 마지막 활성화 함수)\n",
        "\n",
        "target_layer = 'layer4.1.act2'\n",
        "\n",
        "# Grad-CAM 시각화 실행 (예: 인덱스 3의 이미지를 시각화)\n",
        "\n",
        "image_index = 3\n",
        "\n",
        "visualize_gradcam(model.model, device, test_loader, target_layer=target_layer, image_index=image_index)"
      ],
      "metadata": {
        "id": "V6AN15xz4V-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}